+++
title = 'Semantic Cache using LLMs'
date = 2024-03-11T12:52:32+05:30
description =  "Benifits of Semantic Cache"
tags = ["GENAI", "Inference"]
categories = ["GenAI"]
ShowToc =  false
+++


Nvidia is performing very well for the past 4 years with this AI boom and their GPUs are used every where. Recently, Groq, LA based startup came with their own AI chips which can be used during the inference time and their response time quite remarkable.
![Image 1](cover2.jpg) 

{{<highlight python>}}
print('Hello')
{{</highlight>}}