[{"content":"Nvidia is performing very well for the past 4 years with this AI boom and their GPUs are used every where. Recently, Groq, LA based startup came with their own AI chips which can be used during the inference time and their response time quite remarkable. 1 print(\u0026#39;Hello\u0026#39;) ","date":"2024-03-13T12:52:32+05:30","permalink":"http://localhost:1313/sampleblog/post/groq/","title":"Does Groq stops dream run of Nvidia?"},{"content":"Nvidia is performing very well for the past 4 years with this AI boom and their GPUs are used every where. Recently, Groq, LA based startup came with their own AI chips which can be used during the inference time and their response time quite remarkable.\n1 2 3 4 import time start = time.time() time.sleep(3) print(f\u0026#39;Time: {time.time() - start}\u0026#39;) This is an inline mathematical expression: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887$\nBlock math $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n$$ f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi),e^{2 \\pi i \\xi x},d\\xi $$\n","date":"2024-03-13T12:52:32+05:30","image":"http://localhost:1313/sampleblog/post/logistic/cover_huec3c3e34981507583e214021ad1b9a4b_12942_120x120_fill_q75_box_smart1.jpg","permalink":"http://localhost:1313/sampleblog/post/logistic/","title":"Logistic Regression special case of GLM"},{"content":"Nvidia is performing very well for the past 4 years with this AI boom and their GPUs are used every where. Recently, Groq, LA based startup came with their own AI chips which can be used during the inference time and their response time quite remarkable. 1 print(\u0026#39;Hello\u0026#39;) ","date":"2024-03-11T12:52:32+05:30","permalink":"http://localhost:1313/sampleblog/post/semantic/","title":"Semantic Cache using LLMs"}]